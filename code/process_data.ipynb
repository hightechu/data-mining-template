{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "process_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5wIzZLcePzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MrL4i74e_lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Libraries\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from google.colab import files\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dXcWVeufUV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_data = pd.read_csv('/content/IMDb_movies.csv', header=0)\n",
        "# Only English movies \n",
        "movie_data = movie_data.drop(movie_data.index[movie_data['language'] !='English'])\n",
        "# use \"title\", \"genre\", \"descrition\" only\n",
        "movie_data = movie_data.drop([\"language\",\"imdb_title_id\", \"year\",\"original_title\", \"date_published\",\"duration\", \"country\", \"writer\", \"production_company\", \"actors\", \"avg_vote\", \"director\", \"votes\", \"budget\", \"usa_gross_income\", \"worlwide_gross_income\", \"metascore\",\"reviews_from_users\", \"reviews_from_critics\"], axis=1)\n",
        "print(movie_data.shape)\n",
        "movie_data.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xk-vDkitmX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use only one genre for classification\n",
        "genres = []\n",
        "index = 0\n",
        "for movie in movie_data['genre']:\n",
        "  if re.match(\".*,.*\", movie):\n",
        "    genres = movie.split(\", \")\n",
        "    for i in range(len(genres)):\n",
        "      # See if sci-fi or fantasy is included in the genre list\n",
        "      if genres[i] == 'Fantasy' or genres[i] == 'Sci-Fi':\n",
        "        movie_data.iloc[index]['genre'] = genres[i]\n",
        "      elif i == len(genres)-1:\n",
        "        movie_data.iloc[index]['genre'] = genres[i]\n",
        "      else:\n",
        "        continue\n",
        "          \n",
        "\n",
        "  index += 1\n",
        "\n",
        "movie_data = movie_data[(movie_data.genre == 'Fantasy') | (movie_data[:17000].genre == 'Sci-Fi')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_U0UsKa4jTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_data.genre.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e7jUxnzN6vW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code from https://www.machinelearningplus.com/nlp/lemmatization-examples-python/\n",
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "lem = WordNetLemmatizer()\n",
        "def lemmaSentence(sentence):\n",
        "    token_words=word_tokenize(sentence)\n",
        "    lemma_sentence = [lem.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence)]\n",
        "    return \" \".join(lemma_sentence)\n",
        "\n",
        "index = 0\n",
        "for movie in movie_data['description']:\n",
        "  movie_data.iloc[index]['description'] = lemmaSentence(str(movie_data.iloc[index]['description']))\n",
        "  index += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVJhGlcTOhT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(movie_data['genre'].shape)\n",
        "movie_data['genre'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dkhOFQ2jGIyS",
        "colab": {}
      },
      "source": [
        "# Change data into a Document-Term Matrix(DTM)\n",
        "data = movie_data['description'].values.astype('U')\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "vectorizer = CountVectorizer(stop_words = 'english', strip_accents='unicode', tokenizer = token.tokenize)\n",
        "X = vectorizer.fit_transform(data)\n",
        "#print(vectorizer.get_feature_names())\n",
        "# save as csv for student use\n",
        "pd.DataFrame(X.toarray()).to_csv(\"movie_descriptions.csv\", header=vectorizer.get_feature_names())\n",
        "files.download(\"movie_descriptions.csv\")\n",
        "\n",
        "#print(movie_data['genre'])\n",
        "movie_data['genre'].to_csv('movie_genres.csv', index=False)\n",
        "files.download(\"movie_genres.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}